<!DOCTYPE html>
<html prefix="og: http://ogp.me/ns#"><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Learning to Learn – The Berkeley Artificial Intelligence Research Blog</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="The BAIR Blog">
    <meta name="author" content="Daniel Seita">
    <meta name="keywords" content="">
    <link rel="canonical" href="http://bair.berkeley.edu/blog/2017/07/18/learning-to-learn/">
    <link rel="alternate" type="application/rss+xml" title="RSS Feed for The Berkeley Artificial Intelligence Research Blog" href="http://bair.berkeley.edu/blog/feed.xml">
    <link rel="stylesheet" href="Learning%20to%20Learn%20%E2%80%93%20The%20Berkeley%20Artificial%20Intelligence%20Research%20Blog_files/pixyll.css" type="text/css">
    <link rel="stylesheet" href="Learning%20to%20Learn%20%E2%80%93%20The%20Berkeley%20Artificial%20Intelligence%20Research%20Blog_files/bair-blog.css" type="text/css">

    <!-- Fonts -->
    <link href="Learning%20to%20Learn%20%E2%80%93%20The%20Berkeley%20Artificial%20Intelligence%20Research%20Blog_files/css.css" rel="stylesheet" type="text/css">
    <link href="Learning%20to%20Learn%20%E2%80%93%20The%20Berkeley%20Artificial%20Intelligence%20Research%20Blog_files/css_002.css" rel="stylesheet" type="text/css">
    
      <link href="Learning%20to%20Learn%20%E2%80%93%20The%20Berkeley%20Artificial%20Intelligence%20Research%20Blog_files/font-awesome.css" rel="stylesheet">
    

    <!-- Open Graph -->
    <!-- From: https://github.com/mmistakes/hpstr-jekyll-theme/blob/master/_includes/head.html -->
    <meta property="og:locale" content="en_US">
    <meta property="og:type" content="article">
    <meta property="og:title" content="Learning to Learn">
    <meta property="og:description" content="The BAIR Blog">
    <meta property="og:url" content="http://bair.berkeley.edu/blog/2017/07/18/learning-to-learn/">
    <meta property="og:site_name" content="The Berkeley Artificial Intelligence Research Blog">
    <meta property="og:image" content="http://bair.berkeley.edu/blog/assets/maml/maml.png">
    <meta property="og:image:url" content="http://bair.berkeley.edu/blog/assets/maml/maml.png">

    <script async="" src="Learning%20to%20Learn%20%E2%80%93%20The%20Berkeley%20Artificial%20Intelligence%20Research%20Blog_files/analytics.js"></script><script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        extensions: ["tex2jax.js"],
        jax: ["input/TeX", "output/HTML-CSS"],
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"] ],
          displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
          processEscapes: true
        },
        messageStyle: "none",
        "HTML-CSS": { availableFonts: ["TeX"] }
      });
    </script>
    <script src="Learning%20to%20Learn%20%E2%80%93%20The%20Berkeley%20Artificial%20Intelligence%20Research%20Blog_files/MathJax.js" id="">
    </script>

    <!-- Daniel Seita: I added this to handle Samaneh's post. -->
    <script type="text/javascript">
    function update_im_font1(option_font) {
        document.getElementById("im_font1").src="http://bair.berkeley.edu/static/blog/mcgan/"+option_font+".png";
    }
    function update_im_font2(option_font) {
        document.getElementById("im_font2").src="http://bair.berkeley.edu/static/blog/mcgan/"+option_font+".png";
    }
    function update_im_font3(option_font) {
        document.getElementById("im_font3").src="http://bair.berkeley.edu/static/blog/mcgan/"+option_font+".png";
    }
    function update_im_font4(option_font) {
        document.getElementById("im_font4").src="http://bair.berkeley.edu/static/blog/mcgan/"+option_font+".png";
    }
    </script>


<script type="text/javascript" async="" src="Learning%20to%20Learn%20%E2%80%93%20The%20Berkeley%20Artificial%20Intelligence%20Research%20Blog_files/embed.js"></script></head>

<body class="site">

  <div class="site-wrap">
    <header class="site-header px2 px-responsive">
  <div class="mt2 wrap">
    <div class="measure">
      <div class="blog-logo-container">
        <a href="http://bair.berkeley.edu/blog/"><img class="bair-logo" src="Learning%20to%20Learn%20%E2%80%93%20The%20Berkeley%20Artificial%20Intelligence%20Research%20Blog_files/BAIR_Logo.png"></a>
      </div>
      <nav class="site-nav bair-blog-site-nav">
        <a href="http://bair.berkeley.edu/blog/subscribe/">Subscribe</a>
<a href="http://bair.berkeley.edu/blog/about/">About</a>
<a href="http://bair.berkeley.edu/blog/archive/">Archive</a>

      </nav>
      <div class="clearfix"></div>
      
    </div>
  </div>
</header>


    <div class="post p2 p-responsive wrap" role="main">
      <div class="measure">
        <div class="post-header mb2">
  <h1>Learning to Learn</h1>
  <div class="post-meta">
  
  Chelsea Finn &nbsp;&nbsp;
  
  
  Jul 18, 2017
  
  </div>
</div>

<article class="post-content">
  <p>A key aspect of intelligence is versatility – the capability of doing many
different things. Current AI systems excel at mastering a single skill, such as
Go, Jeopardy, or even helicopter aerobatics. But, when you instead ask an AI
system to do a variety of seemingly simple problems, it will struggle. A
champion Jeopardy program cannot hold a conversation, and an expert helicopter
controller for aerobatics cannot navigate in new, simple situations such as
locating, navigating to, and hovering over a fire to put it out. In contrast, a
human can act and adapt intelligently to a wide variety of new, unseen
situations. How can we enable our artificial agents to acquire such versatility?</p>

<p>There are several techniques being developed to solve these sorts of problems
and I’ll survey them in this post, as well as discuss a recent technique from
our lab, called <a href="http://bair.berkeley.edu/blog/2017/07/18/learning-to-learn/#model-agnostic-meta-learning-maml">model-agnostic
meta-learning</a>. (You can check out the <a href="https://arxiv.org/abs/1703.03400">research paper here</a>, and the code
for the <a href="https://github.com/cbfinn/maml">underlying technique here</a>.)</p>

<p>Current AI systems can master a complex skill from scratch, using an
understandably large amount of time and experience. But if we want our agents to
be able to acquire many skills and adapt to many environments, we cannot afford
to train each skill in each setting from scratch. Instead, we need our agents to
learn how to learn new tasks faster by reusing previous experience, rather than
considering each new task in isolation. This approach of learning to learn, or
meta-learning, is a key stepping stone towards versatile agents that can
continually learn a wide variety of tasks throughout their lifetimes.</p>

<h3 id="so-what-is-learning-to-learn-and-what-has-it-been-used-for">So, what is learning to learn, and what has it been used for?</h3>

<!--more-->

<p>Early approaches to meta-learning date back to the late 1980s and early 1990s,
including <a href="http://people.idsia.ch/~juergen/diploma.html">Jürgen Schmidhuber’s thesis</a> and <a href="http://bengio.abracadoudou.com/publications/pdf/bengio_1991_ijcnn.pdf">work by Yoshua and Samy
Bengio</a>.  Recently meta-learning has become a hot topic, with a flurry of
recent papers, most commonly using the technique for <a href="https://arxiv.org/abs/1502.03492">hyperparameter</a> and
<a href="https://arxiv.org/abs/1703.00441">neural</a> <a href="https://arxiv.org/abs/1703.04813">network</a> <a href="http://www.cantab.net/users/yutian.chen/Publications/ChenEtAl_ICML17_L2L.pdf">optimization</a>, finding <a href="https://arxiv.org/abs/1611.01578">good</a> <a href="https://arxiv.org/abs/1611.02167">network</a>
<a href="https://arxiv.org/abs/1704.08792">architectures</a>, <a href="https://arxiv.org/abs/1606.04080">few</a>-<a href="https://openreview.net/forum?id=rJY0-Kcll">shot</a> <a href="https://arxiv.org/abs/1703.03400">image</a> <a href="https://arxiv.org/abs/1606.02819">recognition</a>, and
<a href="https://arxiv.org/abs/1611.02779">fast</a> <a href="https://arxiv.org/abs/1611.05763">reinforcement</a> <a href="https://arxiv.org/abs/1703.03400">learning</a>.</p>

<p style="text-align:center;">
<img src="Learning%20to%20Learn%20%E2%80%93%20The%20Berkeley%20Artificial%20Intelligence%20Research%20Blog_files/banner.jpg" alt="maml"><br>
<i>Various recent meta-learning approaches.</i>
</p>

<h3 id="few-shot-learning">Few-Shot Learning</h3>

<p><img src="Learning%20to%20Learn%20%E2%80%93%20The%20Berkeley%20Artificial%20Intelligence%20Research%20Blog_files/segway.jpg" alt="maml" width="160" hspace="30" align="right">
In 2015, <a href="https://www.cs.cmu.edu/~rsalakhu/papers/LakeEtAl2015Science.pdf">Brendan Lake et al.</a> published a paper that challenged modern machine
learning methods to be able to learn new concepts from one or a few instances of
that concept. As an example, Lake suggested that humans can learn to identify
“novel two-wheel vehicles” from a single picture (e.g. as shown on the right),
whereas machines cannot generalize a concept from just a single image.  (Humans
can also draw a character in a new alphabet after seeing just one example).
Along with the paper, Lake included a dataset of handwritten characters,
<a href="https://github.com/brendenlake/omniglot">Omniglot</a>, the “transpose” of <a href="http://yann.lecun.com/exdb/mnist/">MNIST</a>, with 1623 character classes,
each with 20 examples. Two deep learning models quickly followed with papers at
ICML 2016 that used <a href="http://proceedings.mlr.press/v48/santoro16.pdf">memory-augmented neural networks</a> and <a href="https://arxiv.org/abs/1603.05106">sequential
generative models</a>; showing it is possible for deep models to learn to learn
from a few examples, though not yet at the level of humans.</p>

<h1 id="how-recent-meta-learning-approaches-work">How Recent Meta-learning Approaches Work</h1>

<p>Meta-learning systems are trained by being exposed to a large number of tasks
and are then tested in their ability to learn new tasks; an example of a task
might be classifying a new image within 5 possible classes, given one example of
each class, or learning to efficiently navigate a new maze with only one
traversal through the maze. This differs from many standard machine learning
techniques, which involve training on a single task and testing on held-out
examples from that task.</p>

<p style="text-align:center;">
<img src="Learning%20to%20Learn%20%E2%80%93%20The%20Berkeley%20Artificial%20Intelligence%20Research%20Blog_files/meta_example.png" alt="maml" width="600"><br>
<i>Example meta-learning set-up for few-shot image classification, visual
adapted from <a href="https://openreview.net/forum?id=rJY0-Kcll">Ravi &amp; Larochelle ‘17</a>.</i>
</p>

<p>During meta-learning, the model is trained to learn tasks in the meta-training
set. There are two optimizations at play – the learner, which learns new tasks,
and the meta-learner, which trains the learner. Methods for meta-learning
have typically fallen into one of three categories: recurrent models, metric
learning, and learning optimizers.</p>

<p><strong>Recurrent Models</strong></p>

<p>These approaches train a recurrent model, e.g. an <a href="http://www.bioinf.jku.at/publications/older/2604.pdf">LSTM</a>, to take in the
dataset sequentially and then process new inputs from the task., In an image
classification setting, this might involve passing in the set of (image, label)
pairs of a dataset sequentially, followed by new examples which must be
classified.</p>

<p style="text-align:center;">
<img src="Learning%20to%20Learn%20%E2%80%93%20The%20Berkeley%20Artificial%20Intelligence%20Research%20Blog_files/recurrent_models.png" alt="maml" width="600"><br>
<i>Recurrent model approach for inputs $\mathbf{x}_t$ and corresponding labels
$y_t$, figure from <a href="http://proceedings.mlr.press/v48/santoro16.pdf">Santoro et al. '16</a>.</i>
</p>

<p>The meta-learner uses gradient descent, whereas the learner simply rolls out the
recurrent network. This approach is one of the most general approaches and has
been used for <a href="http://proceedings.mlr.press/v48/santoro16.pdf">few-shot classification and regression</a>, <a href="https://arxiv.org/abs/1707.03141">and</a>
<a href="https://arxiv.org/abs/1611.02779">meta-reinforcement</a> <a href="https://arxiv.org/abs/1611.05763">learning</a>. Due to its flexibility, this approach
also tends to be less (meta-)efficient than other methods because the learner
network needs to come up with its learning strategy from scratch.</p>

<p><strong>Metric Learning</strong></p>

<p>This approach involves learning a metric space in which learning is particularly
efficient. This approach has mostly been used for few-shot classification.
Intuitively, if our goal is to learn from a small number of example images, than
a simple approach is to compare the image that you are trying to classify with
the example images that you have. But, as you might imagine, comparing images in
pixel space won’t work well. Instead, you can train a <a href="https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf">Siamese network</a> or
perform comparisons in a <a href="https://arxiv.org/abs/1606.04080">learned metric space</a>. Like the previous approach,
meta-learning is performed using gradient descent (or your favorite neural
network optimizer), whereas the learner corresponds to a comparison scheme, e.g.
nearest neighbors, in the meta-learned metric space. These approaches work
<a href="https://arxiv.org/abs/1703.05175">quite</a> <a href="https://arxiv.org/abs/1703.00767">well</a> for few-shot classification, though they have yet to be
demonstrated in other meta-learning domains such as regression or reinforcement
learning.</p>

<p><strong>Learning Optimizers</strong></p>

<p>The final approach is to <a href="http://snowedin.net/tmp/Hochreiter2001.pdf">learn an optimizer</a>. In this method, there is one
network (the meta-learner) which learns to update another network (the learner)
so that the learner effectively learns the task. This approach has been
extensively studied for <a href="https://arxiv.org/abs/1606.01885">better</a> <a href="https://arxiv.org/abs/1606.04474">neural</a> <a href="https://arxiv.org/abs/1703.00441">network</a>
<a href="https://arxiv.org/abs/1703.04813">optimization</a>. The meta-learner is typically a recurrent network so that it
can remember how it previously updated the learner model. The meta-learner can
be trained with reinforcement learning or supervised learning. <a href="https://openreview.net/forum?id=rJY0-Kcll">Ravi &amp;
Larochelle</a> recently demonstrated this approach’s merit for few-shot image
classification, presenting the view that the learner model is an optimization
process that should be learned.</p>

<h1 id="learning-initializations-as-meta-learning">Learning Initializations as Meta-Learning</h1>

<p>Arguably, the biggest success story of transfer learning has been initializing
vision network weights <a href="http://proceedings.mlr.press/v32/donahue14.pdf">using ImageNet pre-training</a>. In particular, when
approaching any new vision task, the well-known paradigm is to first collect
labeled data for the task, acquire a network pre-trained on ImageNet
classification, and then fine-tune the network on the collected data using
gradient descent. Using this approach, neural networks can more effectively
learn new image-based tasks from modestly-sized datasets. However, pre-training
only goes so far. Because the last layers of the network still need to be
heavily adapted to the new task, datasets that are too small, as in the few-shot
setting, will still cause severe overfitting. Furthermore, we unfortunately
don’t have an analogous pre-training scheme for non-vision domains such as
speech, language, and control.<sup id="fnref:pre_training"><a href="#fn:pre_training" class="footnote">1</a></sup> Is there something to learn from
the remarkable success of ImageNet fine-tuning?</p>

<h2 id="model-agnostic-meta-learning-maml">Model-Agnostic Meta-Learning (MAML)</h2>

<p>What if we directly optimized for an initial representation that can be
effectively fine-tuned from a small number of examples? This is exactly the idea
behind our recently-proposed algorithm, model-agnostic meta-learning (MAML).
Like other meta-learning methods, MAML trains over a wide range of tasks. It
trains for a representation that can be quickly adapted to a new task, via a few
gradient steps. The meta-learner seeks to find an initialization that is not
only useful for adapting to various problems, but also can be adapted quickly
(in a small number of steps) and efficiently (using only a few examples). Below
is a visualization – suppose we are seeking to find a set of parameters
$\theta$ that are highly adaptable. During the course of meta-learning (the bold
line), MAML optimizes for a set of parameters such that when a gradient step is
taken with respect to a particular task $i$ (the gray lines), the parameters are
close to the optimal parameters $\theta_i^*$ for task $i$.</p>

<p style="text-align:center;">
<img src="Learning%20to%20Learn%20%E2%80%93%20The%20Berkeley%20Artificial%20Intelligence%20Research%20Blog_files/maml.png" alt="maml" width="400"><br>
<i>Diagram of the MAML approach.</i>
</p>

<p>This approach is quite simple, and has a number of advantages. It doesn’t make
any assumptions on the form of the model. It is quite efficient – there are no
additional parameters introduced for meta-learning and the learner’s strategy
uses a known optimization process (gradient descent), rather than having to come
up with one from scratch. Lastly, it can be easily applied to a number of
domains, including classification, regression, and reinforcement learning.</p>

<p>Despite the simplicity of the approach, we were surprised to find that the
method was able to substantially outperform a number of existing approaches on
popular few-shot image classification benchmarks, Omniglot and
MiniImageNet<sup id="fnref:mini_image"><a href="#fn:mini_image" class="footnote">2</a></sup>, including existing approaches that were much more
complex or domain specific.  Beyond classification, we also tried to learn how
to adapt a simulated robot’s behavior to different goals, akin to the motivation
at the top of this blog post – versatility. To do so, we combined MAML with
policy gradient methods for reinforcement learning. MAML discovered a policy
which let a simulated robot adapt its locomotion direction and speed in a single
gradient update. See videos below:</p>

<p style="text-align:center;">
<img src="Learning%20to%20Learn%20%E2%80%93%20The%20Berkeley%20Artificial%20Intelligence%20Research%20Blog_files/cheetah_direc.gif" alt="maml"><br>
<i>MAML on HalfCheetah.</i>
</p>

<p style="text-align:center;">
<img src="Learning%20to%20Learn%20%E2%80%93%20The%20Berkeley%20Artificial%20Intelligence%20Research%20Blog_files/ant_maml.gif" alt="maml"><br>
<i>MAML on Ant.</i>
</p>

<p>The generality of the method —  it can be combined with any model smooth
enough for gradient-based optimization —  makes MAML applicable to a wide
range of domains and learning objectives beyond those explored in the paper.</p>

<p>We hope that MAML’s simple approach for effectively teaching agents to adapt to
variety of scenarios will bring us one step closer towards developing versatile
agents that can learn a variety of skills in real world settings.</p>

<hr>

<p><em>I would like to thank Sergey Levine and Pieter Abbeel for their valuable
feedback.</em></p>

<p><strong>This last part of this post was based on the following research paper</strong>:</p>

<ul>
  <li><a href="https://arxiv.org/abs/1703.03400">Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks</a>. <br>
C. Finn, P. Abbeel, S. Levine. In ICML, 2017. (<a href="https://arxiv.org/pdf/1703.03400.pdf">pdf</a>, <a href="https://github.com/cbfinn/maml">code</a>)</li>
</ul>

<hr>

<div class="footnotes">
  <ol>
    <li id="fn:pre_training">
      <p>Though, researchers have developed domain-agnostic
initialization schemes to encourage <a href="http://proceedings.mlr.press/v9/glorot10a.html">well</a>-<a href="https://arxiv.org/abs/1602.07868">conditioned</a>
<a href="https://arxiv.org/abs/1312.6120">gradients</a> and using <a href="https://arxiv.org/abs/1511.06856">data-dependent</a> <a href="https://arxiv.org/abs/1511.06422">normalization</a>.&nbsp;<a href="#fnref:pre_training" class="reversefootnote">↩</a></p>
    </li>
    <li id="fn:mini_image">
      <p>Introduced by Vinyals et al. ‘16 and Ravi &amp; Larochelle ‘17, the
MiniImageNet benchmark is the same as Omniglot but uses real RGB images from
a subset of the ImageNet dataset.&nbsp;<a href="#fnref:mini_image" class="reversefootnote">↩</a></p>
    </li>
  </ol>
</div>

</article>

<div class="generic-box">
Subscribe to our <a href="http://bair.berkeley.edu/blog/feed.xml">RSS feed</a>.

  <div class="share-page">
<div class="share-links" style="text-align:center;">
  Spread the word:   
    
      <a class="fa fa-facebook" href="https://facebook.com/sharer.php?u=http://bair.berkeley.edu/blog/2017/07/18/learning-to-learn/" rel="nofollow" target="_blank" title="Share on Facebook"></a>
    

    
      <a class="fa fa-twitter" href="https://twitter.com/intent/tweet?text=Learning%20to%20Learn&amp;url=http://bair.berkeley.edu/blog/2017/07/18/learning-to-learn/" rel="nofollow" target="_blank" title="Share on Twitter"></a>
    

    
      <a class="fa fa-google-plus" href="https://plus.google.com/share?url=http://bair.berkeley.edu/blog/2017/07/18/learning-to-learn/" rel="nofollow" target="_blank" title="Share on Google+"></a>
    

    
      <a class="fa fa-linkedin" href="http://www.linkedin.com/shareArticle?url=http://bair.berkeley.edu/blog/2017/07/18/learning-to-learn/&amp;title=Learning%20to%20Learn" rel="nofollow" target="_blank" title="Share on LinkedIn"></a>
    

    

    

    
      <a class="fa fa-reddit" href="http://reddit.com/submit?url=http://bair.berkeley.edu/blog/2017/07/18/learning-to-learn/&amp;title=Learning%20to%20Learn" rel="nofollow" target="_blank" title="Share on Reddit"></a>
    

    

    
      <a class="fa fa-hacker-news" onclick="parent.postMessage('submit','*')" href="https://news.ycombinator.com/submitlink?u=http://bair.berkeley.edu/blog/2017/07/18/learning-to-learn/&amp;t=Learning%20to%20Learn" rel="nofollow" target="_blank" title="Share on Hacker News"></a>
    
  </div>
</div>


</div>




  <h1>Comments</h1>
  <div id="disqus_thread"></div>
  <script type="text/javascript">
    var disqus_shortname  = 'bair-blog';
    var disqus_identifier = '/2017/07/18/learning-to-learn';
    var disqus_title      = 'Learning to Learn';

    (function() {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>




      </div>
    </div>
  </div>

  <footer class="center">
  <div class="measure">
  </div>
</footer>

  
  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-101338021-1', 'auto');
  ga('send', 'pageview');

</script>

  


</body></html>